{"cells":[{"cell_type":"code","execution_count":null,"id":"a3cac4be","metadata":{"id":"a3cac4be","outputId":"f27b2103-590f-497a-c706-d6bb1afa0411"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing files: 100%|██████████| 8/8 [00:04<00:00,  1.77it/s]"]},{"name":"stdout","output_type":"stream","text":["Saved 230 rows to annotated_nda_para.csv\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# !pip install presidio-analyzer presidio-anonymizer \"spacy>=3.0.0,<4.0.0\" python-docx\n","# !python -m spacy download en_core_web_lg\n","import os\n","import re\n","import zipfile\n","import pandas as pd\n","from tqdm import tqdm\n","from lxml import etree\n","from presidio_analyzer import AnalyzerEngine\n","from presidio_anonymizer import AnonymizerEngine\n","from presidio_anonymizer.entities import OperatorConfig\n","\n","analyzer = AnalyzerEngine()\n","anonymizer = AnonymizerEngine()\n","\n","ENTITIES_TO_REDACT = [\n","    \"PERSON\", \"ORGANIZATION\", \"EMAIL_ADDRESS\", \"PHONE_NUMBER\",\n","    \"DATE_TIME\", \"URL\", \"NRP\"\n","]\n","\n","ORG_PATTERNS = [\n","    r'\\binc\\b',\n","    r'\\bcorporation\\b',\n","    r'\\bllc\\b',\n","    r'\\bcompany\\b',\n","    r'tietoevry',\n","    r'evry usa',\n","    r'investors bank',\n","    r'thoughtspot',\n","    r'old republic general',\n","    r'orgs',\n","    r'vendor',\n","    r'paypal',\n","    r'quantum health'\n","]\n","\n","NS = {\"w\": \"http://schemas.openxmlformats.org/wordprocessingml/2006/main\"}\n","\n","VALID_CATEGORIES = {\n","    \"CONFIDENTIALITY OBLIGATIONS\",\n","    \"REMEDIES\",\n","    \"PRIVACY\",\n","    \"LIMITATION OF LIABILITY\",\n","    \"NON-COMPETITION\",\n","    \"NON-SOLICITATION\",\n","    \"INDEMNIFICATION\",\n","    \"GOVERNING LAW\",\n","    \"SIGNATURES\",\n","}\n","\n","def read_comments_xml(zipf):\n","    candidates = [f for f in zipf.namelist() if \"comments\" in f and f.endswith(\".xml\")]\n","    if not candidates:\n","        return {}\n","    chosen = next((c for c in candidates if c.endswith(\"comments.xml\")), candidates[0])\n","    xml = zipf.read(chosen)\n","    tree = etree.fromstring(xml)\n","    comments = {}\n","    for c in tree.findall(\".//w:comment\", namespaces=NS):\n","        cid = c.get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}id\")\n","        texts = c.xpath(\".//w:t/text()\", namespaces=NS)\n","        full = \" \".join([t.strip() for t in texts if t and t.strip()])\n","        comments[cid] = full\n","    return comments\n","\n","def extract_doc_sentences_and_map(doc_xml):\n","    tree = etree.fromstring(doc_xml)\n","    map_id_to_text = {}\n","    map_id_to_para_texts_for_ref = {}\n","    for p in tree.findall(\".//w:p\", namespaces=NS):\n","        para_text = \"\".join(p.xpath(\".//w:t/text()\", namespaces=NS)).strip()\n","        active_ids = []\n","        for node in p.iter():\n","            tag = etree.QName(node).localname\n","            if tag == \"commentRangeStart\":\n","                cid = node.get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}id\")\n","                if cid and cid not in active_ids:\n","                    active_ids.append(cid)\n","                    map_id_to_text.setdefault(cid, [])\n","            elif tag == \"commentRangeEnd\":\n","                cid = node.get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}id\")\n","                if cid and cid in active_ids:\n","                    active_ids.remove(cid)\n","            elif tag == \"commentReference\":\n","                cid = node.get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}id\")\n","                if cid:\n","                    map_id_to_para_texts_for_ref.setdefault(cid, set()).add(para_text)\n","            elif tag == \"t\":\n","                txt = node.text\n","                if txt and txt.strip():\n","                    for cid in active_ids:\n","                        map_id_to_text.setdefault(cid, []).append(txt.strip())\n","    merged = {cid: \" \".join(txts).strip() for cid, txts in map_id_to_text.items()}\n","    return merged, map_id_to_para_texts_for_ref\n","\n","def parse_category_and_flag(comment_text):\n","    if not comment_text:\n","        return None, None\n","    lines = [ln.strip() for ln in comment_text.strip().splitlines() if ln.strip()]\n","    last_line = lines[-1] if lines else comment_text.strip()\n","    text = last_line.strip()\n","    pattern = r\"^(?P<cat>.*?)\\s*[-:]\\s*(?P<flag>Flag|No\\s*Flag)\\b\"\n","    m = re.match(pattern, text, re.IGNORECASE)\n","    if not m:\n","        return None, None\n","    cat_raw = m.group(\"cat\").strip()\n","    flag_raw = m.group(\"flag\").strip().title()\n","    if any(cat_raw.lower() == valid.lower() for valid in VALID_CATEGORIES):\n","        return cat_raw, \"Flag\" if flag_raw.lower().startswith(\"flag\") else \"No Flag\"\n","    return None, None\n","\n","def pre_clean_orgs(text):\n","    clean_text = text\n","    for pat in ORG_PATTERNS:\n","        clean_text = re.sub(pat, \"[REDACTED_ORG]\", clean_text, flags=re.IGNORECASE)\n","    return clean_text\n","\n","def redact_text(text):\n","    if not text.strip():\n","        return \"\"\n","    text = pre_clean_orgs(text)\n","    results = analyzer.analyze(text=text, language=\"en\", entities=ENTITIES_TO_REDACT)\n","    anonymized = anonymizer.anonymize(\n","        text=text,\n","        analyzer_results=results,\n","        operators={\"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED]\"})}\n","    )\n","    return anonymized.text\n","\n","def clean_sentence(text):\n","    text = text.strip().lower()\n","    text = re.sub(r'\\s+', ' ', text)\n","    text = redact_text(text)\n","    return text\n","\n","def process_docx_file(path):\n","    rows = []\n","    with zipfile.ZipFile(path, \"r\") as z:\n","        comments_map = read_comments_xml(z)\n","        if \"word/document.xml\" not in z.namelist():\n","            return rows\n","        doc_xml = z.read(\"word/document.xml\")\n","        map_id_to_text, map_id_to_para_texts_for_ref = extract_doc_sentences_and_map(doc_xml)\n","\n","        for cid, comment_text in comments_map.items():\n","            category, flag = parse_category_and_flag(comment_text)\n","            if not category:\n","                continue\n","\n","            if cid in map_id_to_text and map_id_to_text[cid].strip():\n","                sentence = map_id_to_text[cid].strip()\n","            else:\n","                paras = map_id_to_para_texts_for_ref.get(cid, set())\n","                sentence = next((p for p in paras if p.strip()), \"\")\n","\n","            paras = map_id_to_para_texts_for_ref.get(cid, set())\n","            paragraph = next((p for p in paras if p.strip()), \"\")\n","\n","            clean_sent = clean_sentence(sentence)\n","            clean_para = clean_sentence(paragraph)\n","\n","            rows.append({\n","                \"source_file\": os.path.basename(path),\n","                \"original_sentence\": sentence,\n","                \"clean_sentence\": clean_sent,\n","                # \"paragraph\": paragraph,\n","                \"clean_paragraph\": clean_para,\n","                \"category\": category,\n","                \"Is_Flag\": flag\n","            })\n","    return rows\n","\n","def process_folder(folder):\n","    all_rows = []\n","    for fname in tqdm(os.listdir(folder), desc=\"Processing files\"):\n","        if fname.lower().endswith(\".docx\"):\n","            fpath = os.path.join(folder, fname)\n","            try:\n","                rows = process_docx_file(fpath)\n","                all_rows.extend(rows)\n","            except Exception as e:\n","                print(f\"Error processing {fname}: {e}\")\n","\n","    df = pd.DataFrame(all_rows)\n","    return df\n","\n","if __name__ == \"__main__\":\n","    folder = \"Annotated Documents\"\n","    out_csv = \"annotated_nda_para.csv\"\n","    df = process_folder(folder)\n","    df = df[~((df[\"Is_Flag\"].str.lower() == \"no flag\") &\n","              (df[\"clean_sentence\"].str.split().str.len() < 3))]\n","    df.to_csv(out_csv, index=False)\n","    print(f\"Saved {len(df)} rows to {out_csv}\")\n"]},{"cell_type":"code","execution_count":null,"id":"b231d584","metadata":{"id":"b231d584"},"outputs":[],"source":["import os\n","import re\n","import zipfile\n","import pandas as pd\n","from tqdm import tqdm\n","from lxml import etree\n","from presidio_analyzer import AnalyzerEngine\n","from presidio_anonymizer import AnonymizerEngine\n","from presidio_anonymizer.entities import OperatorConfig\n","\n","analyzer = AnalyzerEngine()\n","anonymizer = AnonymizerEngine()\n","\n","ENTITIES_TO_REDACT = [\n","    \"PERSON\", \"LOCATION\", \"ORGANIZATION\", \"EMAIL_ADDRESS\", \"PHONE_NUMBER\",\n","    \"DATE_TIME\", \"URL\", \"NRP\"\n","]\n","\n","ORG_PATTERNS = [\n","    r'\\binc\\b',\n","    r'\\bcorporation\\b',\n","    r'\\bllc\\b',\n","    r'\\bcompany\\b',\n","    r'tietoevry',\n","    r'evry usa',\n","    r'investors bank',\n","    r'thoughtspot',\n","    r'old republic general',\n","    r'orgs',\n","    r'vendor',\n","    r'paypal',\n","    r'quantum health'\n","]\n","\n","NS = {\"w\": \"http://schemas.openxmlformats.org/wordprocessingml/2006/main\"}\n","\n","VALID_CATEGORIES = {\n","    \"CONFIDENTIALITY OBLIGATIONS\",\n","    \"REMEDIES\",\n","    \"PRIVACY\",\n","    \"LIMITATION OF LIABILITY\",\n","    \"NON-COMPETITION\",\n","    \"NON-SOLICITATION\",\n","    \"INDEMNIFICATION\",\n","    \"GOVERNING LAW\",\n","    \"SIGNATURES\",\n","}\n","\n","def read_comments_xml(zipf):\n","    candidates = [f for f in zipf.namelist() if \"comments\" in f and f.endswith(\".xml\")]\n","    if not candidates:\n","        return {}\n","    chosen = next((c for c in candidates if c.endswith(\"comments.xml\")), candidates[0])\n","    xml = zipf.read(chosen)\n","    tree = etree.fromstring(xml)\n","    comments = {}\n","    for c in tree.findall(\".//w:comment\", namespaces=NS):\n","        cid = c.get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}id\")\n","        texts = c.xpath(\".//w:t/text()\", namespaces=NS)\n","        full = \" \".join([t.strip() for t in texts if t and t.strip()])\n","        comments[cid] = full\n","    return comments\n","\n","def read_numbering(zipf):\n","    numbering = {}\n","    if \"word/numbering.xml\" not in zipf.namelist():\n","        return numbering\n","    xml = zipf.read(\"word/numbering.xml\")\n","    tree = etree.fromstring(xml)\n","    for abstract_num in tree.findall(\"w:abstractNum\", namespaces=NS):\n","        abs_id = abstract_num.get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}abstractNumId\")\n","        lvl_texts = {}\n","        for lvl in abstract_num.findall(\"w:lvl\", namespaces=NS):\n","            ilvl = lvl.get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}ilvl\")\n","            text = lvl.find(\"w:lvlText\", namespaces=NS)\n","            if text is not None:\n","                lvl_texts[ilvl] = text.get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val\")\n","        numbering[abs_id] = lvl_texts\n","    num_map = {}\n","    for num in tree.findall(\"w:num\", namespaces=NS):\n","        num_id = num.get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}numId\")\n","        abs_id = num.find(\"w:abstractNumId\", namespaces=NS)\n","        if abs_id is not None:\n","            num_map[num_id] = numbering.get(abs_id.get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val\"), {})\n","    return num_map\n","\n","def extract_doc_sentences_and_map(doc_xml, numbering_map):\n","    tree = etree.fromstring(doc_xml)\n","    map_id_to_text = {}\n","    map_id_to_para_texts_for_ref = {}\n","    for p in tree.findall(\".//w:p\", namespaces=NS):\n","        numPr = p.find(\".//w:numPr\", namespaces=NS)\n","        prefix = \"\"\n","        if numPr is not None:\n","            num_id_el = numPr.find(\"w:numId\", namespaces=NS)\n","            ilvl_el = numPr.find(\"w:ilvl\", namespaces=NS)\n","            if num_id_el is not None and ilvl_el is not None:\n","                num_id = num_id_el.get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val\")\n","                ilvl = ilvl_el.get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}val\")\n","                lvl_texts = numbering_map.get(num_id, {})\n","                if ilvl in lvl_texts:\n","                    prefix = lvl_texts[ilvl].replace(\"%1\", str(1))  # 简化为 1\n","        para_text = \"\".join(p.xpath(\".//w:t/text()\", namespaces=NS)).strip()\n","        if prefix and para_text:\n","            para_text = prefix + \" \" + para_text\n","        active_ids = []\n","        for node in p.iter():\n","            tag = etree.QName(node).localname\n","            if tag == \"commentRangeStart\":\n","                cid = node.get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}id\")\n","                if cid and cid not in active_ids:\n","                    active_ids.append(cid)\n","                    map_id_to_text.setdefault(cid, [])\n","            elif tag == \"commentRangeEnd\":\n","                cid = node.get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}id\")\n","                if cid and cid in active_ids:\n","                    active_ids.remove(cid)\n","            elif tag == \"commentReference\":\n","                cid = node.get(\"{http://schemas.openxmlformats.org/wordprocessingml/2006/main}id\")\n","                if cid:\n","                    map_id_to_para_texts_for_ref.setdefault(cid, set()).add(para_text)\n","            elif tag == \"t\":\n","                txt = node.text\n","                if txt and txt.strip():\n","                    for cid in active_ids:\n","                        map_id_to_text.setdefault(cid, []).append(txt.strip())\n","    merged = {cid: \" \".join(txts).strip() for cid, txts in map_id_to_text.items()}\n","    return merged, map_id_to_para_texts_for_ref\n","\n","def parse_category_and_flag(comment_text):\n","    if not comment_text:\n","        return None, None\n","    lines = [ln.strip() for ln in comment_text.strip().splitlines() if ln.strip()]\n","    last_line = lines[-1] if lines else comment_text.strip()\n","    text = last_line.strip()\n","    pattern = r\"^(?P<cat>.*?)\\s*[-:]\\s*(?P<flag>Flag|No\\s*Flag)\\b\"\n","    m = re.match(pattern, text, re.IGNORECASE)\n","    if not m:\n","        return None, None\n","    cat_raw = m.group(\"cat\").strip()\n","    flag_raw = m.group(\"flag\").strip().title()\n","    if any(cat_raw.lower() == valid.lower() for valid in VALID_CATEGORIES):\n","        return cat_raw, \"Flag\" if flag_raw.lower().startswith(\"flag\") else \"No Flag\"\n","    return None, None\n","\n","def pre_clean_orgs(text):\n","    clean_text = text\n","    for pat in ORG_PATTERNS:\n","        clean_text = re.sub(pat, \"[REDACTED_ORG]\", clean_text, flags=re.IGNORECASE)\n","    return clean_text\n","\n","def redact_text(text):\n","    if not text.strip():\n","        return \"\"\n","    text = pre_clean_orgs(text)\n","    results = analyzer.analyze(text=text, language=\"en\", entities=ENTITIES_TO_REDACT)\n","    anonymized = anonymizer.anonymize(\n","        text=text,\n","        analyzer_results=results,\n","        operators={\"DEFAULT\": OperatorConfig(\"replace\", {\"new_value\": \"[REDACTED]\"})}\n","    )\n","    return anonymized.text\n","\n","def clean_sentence(text):\n","    text = text.strip().lower()\n","    text = re.sub(r'\\s+', ' ', text)\n","    text = redact_text(text)\n","    return text\n","\n","def process_docx_file(path):\n","    rows = []\n","    with zipfile.ZipFile(path, \"r\") as z:\n","        comments_map = read_comments_xml(z)\n","        numbering_map = read_numbering(z)\n","        if \"word/document.xml\" not in z.namelist():\n","            return rows\n","        doc_xml = z.read(\"word/document.xml\")\n","        map_id_to_text, map_id_to_para_texts_for_ref = extract_doc_sentences_and_map(doc_xml, numbering_map)\n","        for cid, comment_text in comments_map.items():\n","            category, flag = parse_category_and_flag(comment_text)\n","            if not category:\n","                continue\n","            if cid in map_id_to_text and map_id_to_text[cid].strip():\n","                sentence = map_id_to_text[cid].strip()\n","            else:\n","                paras = map_id_to_para_texts_for_ref.get(cid, set())\n","                sentence = next((p for p in paras if p.strip()), \"\")\n","            paras = map_id_to_para_texts_for_ref.get(cid, set())\n","            paragraph = next((p for p in paras if p.strip()), \"\")\n","            clean_sent = clean_sentence(sentence)\n","            clean_para = clean_sentence(paragraph)\n","            rows.append({\n","                \"source_file\": os.path.basename(path),\n","                \"original_sentence\": sentence,\n","                \"clean_sentence\": clean_sent,\n","                \"clean_paragraph\": clean_para,\n","                \"category\": category,\n","                \"Is_Flag\": flag\n","            })\n","    return rows\n","\n","def process_folder(folder):\n","    all_rows = []\n","    for fname in tqdm(os.listdir(folder), desc=\"Processing files\"):\n","        if fname.lower().endswith(\".docx\"):\n","            fpath = os.path.join(folder, fname)\n","            try:\n","                rows = process_docx_file(fpath)\n","                all_rows.extend(rows)\n","            except Exception as e:\n","                print(f\"Error processing {fname}: {e}\")\n","    df = pd.DataFrame(all_rows)\n","    return df\n","\n","if __name__ == \"__main__\":\n","    folder = \"Annotated Documents\"\n","    out_csv = \"annotated_nda_para.csv\"\n","    df = process_folder(folder)\n","    df = df[~((df[\"Is_Flag\"].str.lower() == \"no flag\") &\n","              (df[\"clean_sentence\"].str.split().str.len() < 3))]\n","    df.to_csv(out_csv, index=False)\n","    print(f\"Saved {len(df)} rows to {out_csv}\")\n"]},{"cell_type":"code","execution_count":null,"id":"1ef071d2","metadata":{"id":"1ef071d2"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}